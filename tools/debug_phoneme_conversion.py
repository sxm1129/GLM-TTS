#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è°ƒè¯• Phoneme åŠŸèƒ½çš„å®é™…è½¬æ¢æ•ˆæœ
æŸ¥çœ‹å¯ç”¨ Phoneme æ—¶æ–‡æœ¬æ˜¯å¦‚ä½•è¢«è½¬æ¢çš„
"""

import sys
import os
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from cosyvoice.cli.frontend import TextFrontEnd

# æµ‹è¯•æ–‡æœ¬ç‰‡æ®µï¼ˆåŒ…å«å¤šéŸ³å­—ï¼‰
TEST_SENTENCES = [
    "ä»Šå¤©æ—©ä¸Šï¼ŒéŸ³ä¹å­¦é™¢çš„å­¦ç”Ÿåœ¨æ“åœºä¸Šæ’é˜Ÿèµ°è¡Œã€‚",
    "é˜Ÿä¼å‰é¢èµ°åœ¨æœ€é•¿çš„é‚£ä¸€è¡Œï¼Œæ˜¯æ–°æ¥çš„è¾…å¯¼å‘˜é•¿è€å¸ˆã€‚",
    "ä»–å§“é‡ï¼Œå´ä¸€ç‚¹ä¹Ÿä¸ä¸¥è‚ƒï¼Œå¤§å®¶éƒ½å«ä»–\"è€ä¹\"ï¼Œå› ä¸ºä»–æ—¢ä¼šå¼¹é’¢ç´ï¼Œåˆä¼šæ‹‰å¤§æç´ï¼Œè¿˜ä¼šè‡ªå·±ç¼–æ›²ã€‚",
    "æƒ³å­¦å¥½éŸ³ä¹ï¼Œä¸åªè¦æŠŠä¹è°±çœ‹æ‡‚ï¼ŒèŠ‚å¥æ•°å¯¹ï¼Œè¿˜è¦æŠŠæ¯ä¸€ä¸ªéŸ³è°ƒå¬å‡†ã€‚",
    "è¿™æ ·åˆ«äººæ‰å¬å¾—èˆ’æœï¼Œå¿ƒé‡Œæ‰è§‰å¾—ä¹ã€‚",
    "æ’ç»ƒå¼€å§‹å‰ï¼Œè€å¸ˆç‰¹æ„è°ƒæ•´äº†ä¸€ä¸‹éŸ³å“çš„éŸ³é‡ï¼ŒåˆæŠŠæ¯ä¸ªäººçš„ç«™ä½é‡æ–°å®‰æ’äº†ä¸€éã€‚",
    "è¦æƒ³æŠŠäº‹æƒ…åŠå¾—æ›´å¥½ï¼Œå°±è¦å­¦ä¼šåˆ†åˆ«è½»é‡ç¼“æ€¥ã€‚",
    "æœ‰æ—¶å€™çœ‹èµ·æ¥å¾ˆé‡è¦çš„äº‹ï¼Œå…¶å®å¹¶ä¸éš¾ï¼›åè€Œæ˜¯é‚£äº›çœ‹ä¸Šå»å¾ˆé‡å¤çš„å°äº‹ï¼Œæœ€è€ƒéªŒäººã€‚",
    "å¤©çªç„¶ç©ºä¸‹èµ·å°é›¨ï¼Œæ“åœºä¸Šæ¸æ¸æ˜¾å‡ºä¸€ç‚¹ç‚¹é›¨ç‚¹çš„æ°´èŠ±ã€‚",
    "åªè¦æŠŠè¯ç­’çš„éŸ³é‡å†è°ƒä¸€è°ƒå°±è¡Œã€‚",
]

def test_phoneme_conversion():
    """æµ‹è¯• Phoneme è½¬æ¢"""
    print("="*80)
    print("Phoneme åŠŸèƒ½è½¬æ¢è°ƒè¯•")
    print("="*80 + "\n")
    
    # åˆ›å»ºå¯ç”¨å’Œç¦ç”¨ Phoneme çš„å‰ç«¯
    frontend_enabled = TextFrontEnd(use_phoneme=True)
    frontend_disabled = TextFrontEnd(use_phoneme=False)
    
    print("æµ‹è¯•æ–‡æœ¬è½¬æ¢å¯¹æ¯”ï¼š\n")
    
    for i, text in enumerate(TEST_SENTENCES, 1):
        print(f"\n{'='*80}")
        print(f"æµ‹è¯• {i}: {text}")
        print(f"{'='*80}")
        
        # æ–‡æœ¬å½’ä¸€åŒ–ï¼ˆç¦ç”¨ Phonemeï¼‰
        normalized_disabled = frontend_disabled.text_normalize(text)
        print(f"\n[ç¦ç”¨ Phoneme] å½’ä¸€åŒ–å: {normalized_disabled}")
        
        # æ–‡æœ¬å½’ä¸€åŒ–ï¼ˆå¯ç”¨ Phonemeï¼‰
        normalized_enabled = frontend_enabled.text_normalize(text)
        print(f"[å¯ç”¨ Phoneme] å½’ä¸€åŒ–å: {normalized_enabled}")
        
        # G2P è½¬æ¢ï¼ˆå¯ç”¨ Phonemeï¼‰
        if frontend_enabled.use_phoneme:
            g2p_result = frontend_enabled.g2p_infer(normalized_enabled)
            print(f"[å¯ç”¨ Phoneme] G2P è½¬æ¢å: {g2p_result}")
            
            # å¯¹æ¯”åŸå§‹æ–‡æœ¬å’Œè½¬æ¢ç»“æœ
            if g2p_result != normalized_enabled:
                print(f"\nğŸ“ è½¬æ¢å·®å¼‚:")
                print(f"  åŸå§‹: {normalized_enabled}")
                print(f"  è½¬æ¢: {g2p_result}")
                
                # æ‰¾å‡ºè¢«æ›¿æ¢çš„å­—ç¬¦
                import re
                phoneme_pattern = r'<\|[^|]+\|>'
                phonemes = re.findall(phoneme_pattern, g2p_result)
                if phonemes:
                    print(f"  éŸ³ç´ æ ‡è®°: {phonemes}")
        
        print()

def analyze_replace_dict():
    """åˆ†ææ›¿æ¢å­—å…¸"""
    print("\n" + "="*80)
    print("G2P æ›¿æ¢å­—å…¸åˆ†æ")
    print("="*80 + "\n")
    
    replace_dict_path = "configs/G2P_replace_dict.jsonl"
    if os.path.exists(replace_dict_path):
        with open(replace_dict_path, 'r', encoding='utf-8') as f:
            replace_dict = {}
            for line in f:
                line = line.strip()
                if not line:
                    continue
                d = json.loads(line)
                replace_dict.update(d)
        
        print(f"æ›¿æ¢å­—å…¸æ¡ç›®æ•°: {len(replace_dict)}")
        print("\næ›¿æ¢è§„åˆ™:")
        for key, value in replace_dict.items():
            print(f"  '{key}' â†’ {value}")
    else:
        print(f"âŒ æ›¿æ¢å­—å…¸æ–‡ä»¶ä¸å­˜åœ¨: {replace_dict_path}")

def analyze_able_list():
    """åˆ†æå¯æ›¿æ¢å­—ç¬¦åˆ—è¡¨"""
    print("\n" + "="*80)
    print("G2P å¯æ›¿æ¢å­—ç¬¦åˆ—è¡¨åˆ†æ")
    print("="*80 + "\n")
    
    able_path = "configs/G2P_able_1word.json"
    if os.path.exists(able_path):
        import json
        with open(able_path, 'r', encoding='utf-8') as f:
            able_list = json.load(f)
        
        print(f"å¯æ›¿æ¢å­—ç¬¦æ€»æ•°: {len(able_list)}")
        
        # æ£€æŸ¥æµ‹è¯•æ–‡æœ¬ä¸­çš„å¤šéŸ³å­—æ˜¯å¦åœ¨åˆ—è¡¨ä¸­
        test_chars = set()
        for text in TEST_SENTENCES:
            for char in text:
                if '\u4e00' <= char <= '\u9fff':  # ä¸­æ–‡å­—ç¬¦
                    test_chars.add(char)
        
        print(f"\næµ‹è¯•æ–‡æœ¬ä¸­çš„ä¸­æ–‡å­—ç¬¦æ•°: {len(test_chars)}")
        
        # æ‰¾å‡ºæµ‹è¯•æ–‡æœ¬ä¸­çš„å¤šéŸ³å­—
        multitone_chars = ['è¡Œ', 'é•¿', 'é‡', 'ä¹', 'é‡', 'åˆ«', 'ç©º', 'è°ƒ', 'æ•°', 'æ˜¾']
        in_able_list = []
        not_in_able_list = []
        
        for char in multitone_chars:
            if char in able_list:
                in_able_list.append(char)
            else:
                not_in_able_list.append(char)
        
        print(f"\nå¤šéŸ³å­—åœ¨å¯æ›¿æ¢åˆ—è¡¨ä¸­:")
        for char in in_able_list:
            print(f"  âœ… '{char}'")
        
        if not_in_able_list:
            print(f"\nå¤šéŸ³å­—ä¸åœ¨å¯æ›¿æ¢åˆ—è¡¨ä¸­:")
            for char in not_in_able_list:
                print(f"  âŒ '{char}'")
    else:
        print(f"âŒ å¯æ›¿æ¢å­—ç¬¦åˆ—è¡¨æ–‡ä»¶ä¸å­˜åœ¨: {able_path}")

if __name__ == "__main__":
    import json
    test_phoneme_conversion()
    analyze_replace_dict()
    analyze_able_list()

